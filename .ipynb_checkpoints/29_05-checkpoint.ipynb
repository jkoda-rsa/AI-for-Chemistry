{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f57227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f02a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/HTL_TABLE.xlsx') \n",
    "smiles_list = df['SMILES'].dropna().tolist() \n",
    "labels = df['PCE (%)'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d61dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_smiles = []\n",
    "unique_labels = []\n",
    "for i, smiles in enumerate(smiles_list):\n",
    "    # Make sure SMILES is a string\n",
    "    if isinstance(smiles, str):\n",
    "        molecule = Chem.MolFromSmiles(smiles)\n",
    "        if molecule is not None:  # Ensures the molecule was created successfully\n",
    "            canonical_smiles = Chem.MolToSmiles(molecule, canonical=True)\n",
    "            if canonical_smiles not in unique_smiles:\n",
    "                unique_smiles.append(canonical_smiles)\n",
    "                unique_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa5e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 209\n",
      "Number of molecular descriptors without invalid values: 197\n"
     ]
    }
   ],
   "source": [
    "from deepchem.feat import RDKitDescriptors\n",
    "featurizer = RDKitDescriptors()\n",
    "features = featurizer.featurize(unique_smiles)\n",
    "print(f\"Number of generated molecular descriptors: {features.shape[1]}\")\n",
    "\n",
    "# Drop the features containing invalid values\n",
    "features = features[:, ~np.isnan(features).any(axis=0)]\n",
    "print(f\"Number of molecular descriptors without invalid values: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91686699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecular descriptors after removing zero-variance features: 145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "features = selector.fit_transform(features)\n",
    "print(f\"Number of molecular descriptors after removing zero-variance features: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "963b28d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, unique_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8acf08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(n_estimators=10, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f84789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost model.\n",
      "RMSE on train set: 1.429, test set: 3.442.\n",
      "R^2 on train set: 0.890, test set: 0.215.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def train_test_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Function that trains a model, and tests it.\n",
    "    Inputs: sklearn model, train_data, test_data\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate RMSE on training and testing\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    model_train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    model_test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    model_train_rmse = model_train_mse ** 0.5\n",
    "    model_test_rmse = model_test_mse ** 0.5\n",
    "\n",
    "    # Calculate R^2 on training and testing\n",
    "    model_train_r2 = r2_score(y_train, y_pred_train)\n",
    "    model_test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"RMSE on train set: {model_train_rmse:.3f}, test set: {model_test_rmse:.3f}.\")\n",
    "    print(f\"R^2 on train set: {model_train_r2:.3f}, test set: {model_test_r2:.3f}.\\n\")\n",
    "\n",
    "\n",
    "# Train and test XGBoost model\n",
    "print(\"Evaluating XGBoost model.\")\n",
    "train_test_model(xgb_reg, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83cb2075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10], \n",
    "    'learning_rate': [0.01, 0.1, 0.2], \n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'reg_lambda': [0.01, 0.1, 1],\n",
    "    # Add more parameters here as needed\n",
    "}\n",
    "\n",
    "# Initialize the grid search\n",
    "grid_search = GridSearchCV(xgb_reg, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c08045d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train set: 1.090, test set: 3.306.\n",
      "R^2 on train set: 0.936, test set: 0.275.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(**best_params)\n",
    "train_test_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b724c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
