{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eee7b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "271ebd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smiles(smiles_list, labels):\n",
    "    unique_smiles = []\n",
    "    unique_labels = []\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        if isinstance(smiles, str):\n",
    "            molecule = Chem.MolFromSmiles(smiles)\n",
    "            if molecule is not None:  \n",
    "                canonical_smiles = Chem.MolToSmiles(molecule, canonical=True)\n",
    "                if canonical_smiles not in unique_smiles:\n",
    "                    unique_smiles.append(canonical_smiles)\n",
    "                    unique_labels.append(labels[i])\n",
    "    \n",
    "    return unique_smiles, unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4822d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from deepchem.feat import RDKitDescriptors\n",
    "\n",
    "def featurize_smiles(smiles_list):\n",
    "    featurizer = RDKitDescriptors()\n",
    "    features = featurizer.featurize(smiles_list)\n",
    "    print(f\"Number of generated molecular descriptors: {features.shape[1]}\")\n",
    "\n",
    "    features = features[:, ~np.isnan(features).any(axis=0)]\n",
    "    print(f\"Number of molecular descriptors without invalid values: {features.shape[1]}\")\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b14fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def remove_zero_variance_features(features, threshold=0.0):\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    features = selector.fit_transform(features)\n",
    "    \n",
    "    print(f\"Number of molecular descriptors after removing zero-variance features: {features.shape[1]}\")\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c45d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def perform_grid_search(X_train, y_train, model, param_grid, cv=5, scoring='r2', n_jobs=-1):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters found: \", best_params)\n",
    "\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4b65db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def train_test_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    model_train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    model_test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    model_train_rmse = model_train_mse ** 0.5\n",
    "    model_test_rmse = model_test_mse ** 0.5\n",
    "\n",
    "    model_train_r2 = r2_score(y_train, y_pred_train)\n",
    "    model_test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"RMSE on train set: {model_train_rmse:.3f}, test set: {model_test_rmse:.3f}.\")\n",
    "    print(f\"R^2 on train set: {model_train_r2:.3f}, test set: {model_test_r2:.3f}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e83018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "11d4baf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 209\n",
      "Number of molecular descriptors without invalid values: 197\n"
     ]
    }
   ],
   "source": [
    "df_htl = pd.read_excel('data/HTL_TABLE.xlsx') \n",
    "smiles_list = df_htl['SMILES'].dropna().tolist() \n",
    "labels = df_htl['PCE (%)'].dropna().tolist()\n",
    "\n",
    "unique_smiles, unique_labels = process_smiles(smiles_list, labels)\n",
    "features = featurize_smiles(unique_smiles)\n",
    "#rz_variance = remove_zero_variance_features(features, threshold=0.0)\n",
    "\n",
    "#max_len = max(len(f) for f in features)\n",
    "#feature_vectors = [np.pad(f, (0, max_len - len(f))) for f in features]\n",
    "\n",
    "X = features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, unique_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7582e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'max_leaf_nodes': [None, 10, 50, 100],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3],\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2, 0.3],\n",
    "    'max_samples': [None, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "\n",
    "#best_params = perform_grid_search(X_train, y_train, ranf_reg, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "#n_estimators=200, max_depth=3, min_samples_leaf=1, min_samples_split=10, bootstrap=True, random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "776e8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train set: 1.669, test set: 3.195.\n",
      "R^2 on train set: 0.850, test set: 0.323.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranf_reg = RandomForestRegressor()\n",
    "train_test_model(ranf_reg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8797f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 0, ['CC(=O)Oc1ccccc1C(=O)O']. Appending empty array\n",
      "Exception message: 'list' object has no attribute 'GetNumAtoms'\n",
      "Failed to featurize datapoint 1, [None]. Appending empty array\n",
      "Exception message: 'list' object has no attribute 'GetNumAtoms'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 0\n",
      "Number of molecular descriptors without invalid values: 0\n",
      "No valid descriptors could be generated for the provided SMILES string: CC(=O)OC1=CC=CC=C1C(O)=O\n"
     ]
    }
   ],
   "source": [
    "new_smiles = 'CC(=O)OC1=CC=CC=C1C(O)=O'\n",
    "\n",
    "# Step 2: Process the smiles string\n",
    "new_smiles_processed = process_smiles([new_smiles], [None])  \n",
    "\n",
    "# Step 3: Featurize the processed smiles string\n",
    "new_features = featurize_smiles(new_smiles_processed)\n",
    "\n",
    "# Check if valid descriptors were generated\n",
    "if new_features.shape[1] > 0:\n",
    "    # Step 4: Pass the featurized smiles string into your model\n",
    "    new_PCE_estimate = ranf_reg.predict(new_features)\n",
    "\n",
    "    # Step 5: Print the PCE estimate\n",
    "    print(f'Estimated PCE for the provided SMILES string is: {new_PCE_estimate[0]}')\n",
    "else:\n",
    "    print(f\"No valid descriptors could be generated for the provided SMILES string: {new_smiles}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d53dc08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 209\n",
      "Number of molecular descriptors without invalid values: 209\n",
      "209\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 209 features, but RandomForestRegressor is expecting 197 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Let's say we have a smiles string for which we want to predict the PCE\u001b[39;00m\n\u001b[1;32m     15\u001b[0m smiles_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO(C1=CC=C(C=C1)N(C2=CC=C3C4=CC=C(C=C4C5(C3=C2)C6=CC(=CC=C6C7=CC=C(C=C75)N(C8=CC=C(OC)C=C8)C=9C=CC=CC9OC)N(C\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m10=CC=C(OC)C=C\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m10)C=\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m11C=CC=CC\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m11OC)N(C\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m12=CC=C(OC)C=C\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m12)C=\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m13C=CC=CC\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m13OC)C=\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m14C=CC=CC\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m14OC)C\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# replace this with your own smiles string\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m estimated_pce \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_pce\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmiles_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[128], line 10\u001b[0m, in \u001b[0;36mestimate_pce\u001b[0;34m(smiles_str)\u001b[0m\n\u001b[1;32m      7\u001b[0m feature_vector \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# estimate PCE\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m pce \u001b[38;5;241m=\u001b[39m \u001b[43mranf_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pce\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 209 features, but RandomForestRegressor is expecting 197 features as input."
     ]
    }
   ],
   "source": [
    "def estimate_pce(smiles_str):\n",
    "    processed_smiles = process_smiles([smiles_str], [None])[0]\n",
    "    features = featurize_smiles(processed_smiles)\n",
    "    print(features.shape[1])\n",
    "\n",
    "    # reshape the feature vector\n",
    "    feature_vector = features.reshape(1, -1)\n",
    "\n",
    "    # estimate PCE\n",
    "    pce = ranf_reg.predict(feature_vector)\n",
    "\n",
    "    return pce\n",
    "\n",
    "# Let's say we have a smiles string for which we want to predict the PCE\n",
    "smiles_str = 'O(C1=CC=C(C=C1)N(C2=CC=C3C4=CC=C(C=C4C5(C3=C2)C6=CC(=CC=C6C7=CC=C(C=C75)N(C8=CC=C(OC)C=C8)C=9C=CC=CC9OC)N(C%10=CC=C(OC)C=C%10)C=%11C=CC=CC%11OC)N(C%12=CC=C(OC)C=C%12)C=%13C=CC=CC%13OC)C=%14C=CC=CC%14OC)C'  # replace this with your own smiles string\n",
    "\n",
    "estimated_pce = estimate_pce(smiles_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7087ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 209\n",
      "Number of molecular descriptors without invalid values: 209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.22947331e+00,  6.22947331e+00,  7.10360401e-01,\n",
       "        -1.06470011e+00,  7.28259719e-02,  1.22545500e+03,\n",
       "         1.15691100e+03,  1.22450372e+03,  4.60000000e+02,\n",
       "         0.00000000e+00,  1.42364996e-01, -4.96765883e-01,\n",
       "         4.96765883e-01,  1.42364996e-01,  2.04301075e-01,\n",
       "         3.97849462e-01,  5.91397849e-01,  1.64828791e+01,\n",
       "         9.69803364e+00,  2.52990590e+00, -2.35006803e+00,\n",
       "         2.65873508e+00, -2.27210932e+00,  6.00307315e+00,\n",
       "         4.14228213e-01,  1.50613533e+00,  1.12246120e+00,\n",
       "         4.10959846e+03,  6.37447612e+01,  5.29582526e+01,\n",
       "         5.29582526e+01,  4.57408061e+01,  3.06292664e+01,\n",
       "         3.06292664e+01,  2.24906842e+01,  2.24906842e+01,\n",
       "         1.78685515e+01,  1.78685515e+01,  1.36284555e+01,\n",
       "         1.36284555e+01, -1.17600000e+01,  1.50613533e+00,\n",
       "         5.88953762e+01,  2.49021226e+01,  1.01264263e+01,\n",
       "         5.42279953e+02,  5.74945426e+01,  4.59960947e+01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.27964048e+01,\n",
       "         2.38631358e+02,  4.54990902e+01,  8.50429159e+01,\n",
       "         3.78949036e+01,  6.82486353e+01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.41499047e+00,\n",
       "         7.64780193e+01,  2.89173957e+02,  0.00000000e+00,\n",
       "         6.82499006e+01,  5.74945426e+01,  6.82486353e+01,\n",
       "         4.59960947e+01,  0.00000000e+00,  5.68783803e+01,\n",
       "         5.41499047e+00,  0.00000000e+00,  2.22538060e+01,\n",
       "         2.66920151e+02,  0.00000000e+00,  2.22538060e+01,\n",
       "         0.00000000e+00,  8.68000000e+01,  5.41499047e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.29980473e+01,  1.35754295e+02,  0.00000000e+00,\n",
       "         5.68783803e+01,  9.70618731e+01,  1.89457917e+02,\n",
       "         3.78949036e+01,  4.79520717e+01,  0.00000000e+00,\n",
       "         9.10144115e+00,  0.00000000e+00,  1.82693163e+01,\n",
       "         5.81953212e+00,  9.31269424e+01,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.36473630e+01,  1.11111111e-01,\n",
       "         9.30000000e+01,  0.00000000e+00,  1.20000000e+01,\n",
       "         2.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n",
       "         1.20000000e+01,  0.00000000e+00,  1.20000000e+01,\n",
       "         1.20000000e+01,  0.00000000e+00,  1.20000000e+01,\n",
       "         2.00000000e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.40000000e+01,  1.99781000e+01,\n",
       "         3.73888000e+02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  4.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.20000000e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.20000000e+01,\n",
       "         0.00000000e+00,  1.00000000e+01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurize_smiles(smiles_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47b80e",
   "metadata": {},
   "source": [
    " # Multiple Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36eaf0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of SMILES list: 221\n",
      "Length of PCE (%) list: 221\n",
      "Length of Voc (V) list: 221\n",
      "Length of Jsc (mA cm-2) list: 221\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['SMILES', 'PCE (%)', 'Jsc (mA cm-2)', 'Voc (V)', 'FF (%)'])\n",
    "\n",
    "# Convert columns to lists\n",
    "smiles_list = df['SMILES'].tolist()\n",
    "labels1 = df['PCE (%)'].tolist()\n",
    "labels2 = df['Voc (V)'].tolist()\n",
    "labels3 = df['Jsc (mA cm-2)'].tolist()\n",
    "#labels4 = df['ΔΕ (eV)'].tolist()\n",
    "labels5 = df['FF (%)'].tolist()\n",
    "\n",
    "print(f'Length of SMILES list: {len(smiles_list)}')\n",
    "print(f'Length of PCE (%) list: {len(labels1)}')\n",
    "print(f'Length of Voc (V) list: {len(labels2)}')\n",
    "print(f'Length of Jsc (mA cm-2) list: {len(labels3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac7be333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 209\n",
      "Number of molecular descriptors without invalid values: 197\n",
      "Number of molecular descriptors after removing zero-variance features: 145\n",
      "Training score: 0.8809843491245112\n",
      "Test score: 0.018096244346711032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_excel('data/HTL_TABLE.xlsx') \n",
    "smiles_list = df['SMILES'].dropna().tolist() \n",
    "\n",
    "labels1 = df['PCE (%)'].dropna().tolist()\n",
    "labels2 = df['Voc (V)'].dropna().tolist()\n",
    "labels3 = df['Jsc (mA cm-2)'].tolist()\n",
    "#labels4 = df['ΔΕ (eV)'].tolist()\n",
    "labels5 = df['FF (%)'].tolist()\n",
    "\n",
    "\n",
    "unique_smiles = []\n",
    "unique_labels = []\n",
    "for i, smiles in enumerate(smiles_list):\n",
    "    # Make sure SMILES is a string\n",
    "    if isinstance(smiles, str):\n",
    "        molecule = Chem.MolFromSmiles(smiles)\n",
    "        if molecule is not None:  # Ensures the molecule was created successfully\n",
    "            canonical_smiles = Chem.MolToSmiles(molecule, canonical=True)\n",
    "            if canonical_smiles not in unique_smiles:\n",
    "                unique_smiles.append(canonical_smiles)\n",
    "                unique_labels.append([labels3[i], labels1[i], labels5[i], labels2[i]])\n",
    "\n",
    "features = featurize_smiles(unique_smiles)\n",
    "feature_vectors = remove_zero_variance_features(features, threshold=0.0)\n",
    "\n",
    "# Ensure all feature vectors are the same length by padding with zeros\n",
    "max_len = max(len(f) for f in feature_vectors)\n",
    "feature_vectors = [np.pad(f, (0, max_len - len(f))) for f in feature_vectors]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(feature_vectors, unique_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6.1: Feed the feature vectors to a machine learning model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "print('Training score:', model.score(features_train, labels_train))\n",
    "print('Test score:', model.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81cba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
